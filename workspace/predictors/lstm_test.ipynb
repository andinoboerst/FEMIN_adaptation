{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../results/training_in_forces.npy\", \"rb\") as f:\n",
    "    training_in = np.load(f)\n",
    "\n",
    "with open(f\"../results/training_out_forces.npy\", \"rb\") as f:\n",
    "    training_out = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_in.shape\n",
    "\n",
    "trainX = torch.tensor(training_in, dtype=torch.float32)\n",
    "trainY = torch.tensor(training_out[:, -1, :], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, h0=None, c0=None):\n",
    "        # If hidden and cell states are not provided, initialize them as zeros\n",
    "        if h0 is None or c0 is None:\n",
    "            h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(x.device)\n",
    "            c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(x.device)\n",
    "        \n",
    "        # Forward pass through LSTM\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])  # Selecting the last output\n",
    "        return out, hn, cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 42])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 121000528.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[1;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, trainY)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Detach hidden and cell states to prevent backpropagation through the entire sequence\u001b[39;00m\n",
      "File \u001b[0;32m/dolfinx-env/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dolfinx-env/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dolfinx-env/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize model, loss, and optimizer\n",
    "model = LSTMModel(input_dim=42, hidden_dim=100, layer_dim=1, output_dim=42)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1000\n",
    "h0, c0 = None, None  # Initialize hidden and cell states\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    outputs, h0, c0 = model(trainX, h0, c0)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = criterion(outputs, trainY)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Detach hidden and cell states to prevent backpropagation through the entire sequence\n",
    "    h0 = h0.detach()\n",
    "    c0 = c0.detach()\n",
    "\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 400, 42])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX[-2:-1, :400, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_400, h400, c400 = model(trainX[-1:, :400, :], None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_401, _, _ = model(trainX[-1:, 400:401, :], h400, c400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_401_comp, _, _ = model(trainX[-1:, :401, :], None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = training_in[-1, 400, :]\n",
    "predicted_test, _, _ = model(torch.tensor(predict_test[None, None, :], dtype=torch.float32), h400, c400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.3041e-02, -1.7005e+02,  6.7185e-02, -1.6943e+02,  1.1316e-01,\n",
       "         -1.6972e+02,  1.0122e-01, -1.6944e+02, -2.9860e-02, -1.7122e+02,\n",
       "         -1.0494e-01, -1.6915e+02, -1.5843e-01, -1.7043e+02, -1.3934e-01,\n",
       "         -1.6981e+02, -1.1565e-01, -1.6958e+02, -8.8278e-02, -1.6972e+02,\n",
       "         -5.0606e-02, -1.7051e+02, -4.0793e-02, -1.7044e+02, -4.6974e-02,\n",
       "         -1.7028e+02, -5.1964e-02, -1.7052e+02, -4.6195e-02, -1.6997e+02,\n",
       "         -5.1488e-02, -1.6970e+02, -3.3158e-02, -1.6926e+02,  2.4980e-02,\n",
       "         -1.6986e+02,  7.2152e-02, -1.7043e+02,  8.1653e-02, -1.7038e+02,\n",
       "          8.4323e-02, -1.6942e+02]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.3040e-02, -1.7005e+02,  6.7186e-02, -1.6943e+02,  1.1316e-01,\n",
       "         -1.6972e+02,  1.0122e-01, -1.6944e+02, -2.9859e-02, -1.7122e+02,\n",
       "         -1.0494e-01, -1.6915e+02, -1.5843e-01, -1.7043e+02, -1.3934e-01,\n",
       "         -1.6981e+02, -1.1565e-01, -1.6958e+02, -8.8278e-02, -1.6972e+02,\n",
       "         -5.0607e-02, -1.7051e+02, -4.0796e-02, -1.7044e+02, -4.6976e-02,\n",
       "         -1.7028e+02, -5.1965e-02, -1.7052e+02, -4.6196e-02, -1.6997e+02,\n",
       "         -5.1488e-02, -1.6970e+02, -3.3158e-02, -1.6927e+02,  2.4981e-02,\n",
       "         -1.6986e+02,  7.2154e-02, -1.7043e+02,  8.1653e-02, -1.7038e+02,\n",
       "          8.4325e-02, -1.6942e+02]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.3040e-02, -1.7005e+02,  6.7186e-02, -1.6943e+02,  1.1316e-01,\n",
       "         -1.6972e+02,  1.0122e-01, -1.6944e+02, -2.9859e-02, -1.7122e+02,\n",
       "         -1.0494e-01, -1.6915e+02, -1.5843e-01, -1.7043e+02, -1.3934e-01,\n",
       "         -1.6981e+02, -1.1565e-01, -1.6958e+02, -8.8278e-02, -1.6972e+02,\n",
       "         -5.0607e-02, -1.7051e+02, -4.0796e-02, -1.7044e+02, -4.6976e-02,\n",
       "         -1.7028e+02, -5.1965e-02, -1.7052e+02, -4.6196e-02, -1.6997e+02,\n",
       "         -5.1488e-02, -1.6970e+02, -3.3158e-02, -1.6927e+02,  2.4981e-02,\n",
       "         -1.6986e+02,  7.2154e-02, -1.7043e+02,  8.1653e-02, -1.7038e+02,\n",
       "          8.4325e-02, -1.6942e+02]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_401_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.3040e-02, -1.7005e+02,  6.7186e-02, -1.6943e+02,  1.1316e-01,\n",
       "         -1.6972e+02,  1.0122e-01, -1.6944e+02, -2.9859e-02, -1.7122e+02,\n",
       "         -1.0494e-01, -1.6915e+02, -1.5843e-01, -1.7043e+02, -1.3934e-01,\n",
       "         -1.6981e+02, -1.1565e-01, -1.6958e+02, -8.8278e-02, -1.6972e+02,\n",
       "         -5.0607e-02, -1.7051e+02, -4.0796e-02, -1.7044e+02, -4.6976e-02,\n",
       "         -1.7028e+02, -5.1965e-02, -1.7052e+02, -4.6196e-02, -1.6997e+02,\n",
       "         -5.1488e-02, -1.6970e+02, -3.3158e-02, -1.6927e+02,  2.4981e-02,\n",
       "         -1.6986e+02,  7.2154e-02, -1.7043e+02,  8.1653e-02, -1.7038e+02,\n",
       "          8.4325e-02, -1.6942e+02]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dolfinx-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
